\batchmode
\makeatletter
\makeatother
\newcommand{\integral}{\int}
%\documentclass[useAMS,usenatbib]{biom}
\documentclass[referee,useAMS,usenatbib]{biom}
\usepackage[latin9]{inputenc}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\usepackage{url}
\usepackage{bm}
%\usepackage{esint}
\usepackage[authoryear]{natbib}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
<<echo=F>>=
  if(exists(".orig.enc")) options(encoding = .orig.enc)
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.

\usepackage{setspace}\usepackage{bm}\usepackage{Sweave}

%\documentclass[useAMS,usenatbib,referee]{biom}

%\usepackage[latin9]{inputenc}
%\usepackage{geometry}
%\geometry{verbose}

%\usepackage{amssymb}
%\usepackage{esint}
%\usepackage{Sweave}
%\usepackage{amsthm}\usepackage{epsfig}\usepackage{psfrag}

\setcounter{footnote}{2}

\makeatother

%\begin{document}
\SweaveOpts{concordance=TRUE}
%\label{firstpage}


\title[A Random Scale Detection Function]{Distance Sampling with a Random Scale Detection Function}


\author{\textbf{Cornelia S.\ Oedekoven}$^{\mathbf{1,*}}$\email{cornelia@mcs.st-and.ac.uk}, \textbf{Jeff
Laake}$^{\mathbf{2}}$ and \textbf{Hans J.\ Skaug}$^{\mathbf{3}}$\\
 $^{(1)}$School of Mathematics and Statistics, University of St Andrews, CREEM, \\
The Observatory, Buchanan Gardens,  St Andrews, KY16 9LZ, UK\\
 $^{(2)}$Alaska Fisheries Science Center, NOAA, 7600 Sand Point Way N.E., Seattle, WA, USA
98115-6349\\
 $^{(3)}$Faculty of Mathematics and Natural Sciences, Johannes Bruns gate 12\\
 University of Bergen, N-5008 Bergen, Norway\\
}

\begin{document}

\label{firstpage}

\begin{abstract}
\noindent Distance sampling was developed to estimate wildlife abundance
from observational surveys with detection probabilities in the search
area of less than one. We present novel analysis methods for estimating
this detection probability that make use of random effects models
to allow for unmodeled heterogeneity in detection. The scale parameter
of the half-normal detection function is modeled with an intercept
and a normal error term for each detection with mean zero and unknown
standard deviation. In contrast to conventional distance sampling
methods, our approach can deal with long-tailed detection functions
without truncation. Compared to a fixed effect covariate approach,
we think of the random effect as a covariate with unknown values and
integrate over the random effect. We expand the random scale to a
mixed scale model by adding fixed effect covariates. We analyse simulated
data where subsets of the data originated from normal models with
different intercepts. Here, the random scale and mixed scale models
produce similar overall abundance estimates. However, when stratified
abundance estimates are desired, the mixed model approach produces
estimates that are closer to the truth than the random scale approach.
We illustrate the mixed effect modelling approach with harbor porpoise
vessel survey data and propose that a random or mixed effect model
of the detection function scale be adopted as a standard approach
for fitting detection functions in distance sampling.\\
\end{abstract}

\begin{keywords}
Abundance estimation; Heterogeneity in detection probabilities;
Half-normal; Mixed effects
\end{keywords}

\maketitle

\label{firstpage}

\section{Introduction}

<<echo=FALSE>>=
library(RandomScale)
library(R2admb)
setEPS()
Sys.setenv(PATH = paste("c:/admb/bin;c:admb/utilities;c:/MinGW/bin;", 
            Sys.getenv("PATH"), sep = ";"))
Sys.setenv(ADMB_HOME = "c:/admb")
set.seed(123)
@\\
\noindent Distance sampling was developed to estimate wildlife abundance
from observational surveys with visibility bias \citep{Buckland2001}.
This visibility bias may occur in the case that the observer misses
objects within the search area resulting in average detection probabilities
that are less than one. In this paper we present novel analysis methods
for estimating this detection probability that make use of random
effects models.

The two most common distance sampling methods are line and point transect
sampling. For line transects, the observer travels down the line and
records all perpendicular distances from the line to the detections
of the species of interest. For point transects, the observer remains
at the point for a fixed amount of time and records all radial distances
from the point to the detections of the species of interest. For brevity,
we will speak of objects below where each object may consist of single
animals (or plants) or clusters of these. Here, we assume that all
objects on the line or point are detected with certainty.

Using conventional distance sampling (CDS) methods, the first step
of analysing distance sampling data generally consists of fitting
a probability density function (pdf) $f(x)$ to the sample of observed
distances to infer the detection probability for the sample \citep{Buckland2001}.
This function depends on two functions, $g(x)$ and $h(x)$, where
$g(x)$ is the probability of seeing an object at distance \textit{x}
given the object is at that distance and $h(x)$ is the probability
that the object is at distance \textit{x}. The pdf $f(x)$ is given
by:

\[
f(x)=\frac{g(x)h(x)}{\int{g(u)h(u)du}}\quad,
\]

\noindent which is the probability density for seeing an object at
\textit{x} conditional on that it was seen somewhere. From the assumption
of random line or point placement \citep{Buckland2001}, we assume
uniform density locally with respect to \textit{x} over a sample of
lines or points. For lines, this means that $h(x)=1/w$ where \textit{w}
is the strip half-width and for points $h(x)=2\pi x/(\pi w^{2})$
where \textit{w} is the radius of the circle. From here on, we will
refer to line transect sampling although the methods we describe are
the same for points with the adjustment for a different $h(x)$. With
$h(x)=1/w$, $f(x)$ simplifies to

\begin{equation}
f(x)=\frac{g(x)}{\int_{0}^{w}g(u)du}\quad.\label{eq:lt pdf}
\end{equation}


With the additional assumption that detection at \textit{x}=0 is perfect
(i.e.\ $g(0)$=1), $f(x)$ evaluated at distance zero is given by:

\begin{equation}
f(0)=\frac{1}{\int_{0}^{w}g(u)du}\quad.\label{eq:lt pdf-1}
\end{equation}


\noindent For \textit{n} observations from strips of total length
\textit{L} and width 2\textit{w}, object density within the total
search area is:

\begin{equation}
D=\frac{n}{2wLp}=\frac{n}{2wL\int_{0}^{w}g(u)\frac{1}{w}du}=\frac{nf(0)}{2L}\quad,\label{eq:density}
\end{equation}


\noindent where $p=\int_{0}^{w}g(u)\frac{1}{w}du$ is the average
detection probability. Note that \textit{n} refers to the number of
detected objects. In the case that objects consist of clusters of
size larger than one, eq \ref{eq:density} needs to be multiplied
with the expected cluster size to estimate density of individuals.
Using the design-based approach from \citep{Buckland2001}, object
abundance in the study area may be obtained by multiplying \textit{D}
from eq \ref{eq:density} with the size of the study area. The quantity
$\mu=\int_{0}^{w}g(u)du=wp$ is called the effective strip width (ESW),
but is actually a half-strip width for each side of the line. 

However, when not considering cluster size, \textit{p} is the only
quantity from eq \ref{eq:density} that requires estimation, while
\textit{n}, \textit{w} and \textit{L} are known. Hence, it is important
to fit a flexible detection function that allows unbiased estimation
of \textit{p}. Using CDS methods, this was generally accomplished
by comparing the fits of multiple key-adjustment term combinations
(see section \ref{s:exist} for details). However, recently two main
new methods have been developed that allow modeling heterogeneity
in detection probabilities by including observable covariates in the
detection function model \citep{Marques2003} or by using mixture
models (\citeyear{Miller}, in prep).

In the following we begin by summarising these existing methods for
fitting detection functions including their strengths and weaknesses
(section \ref{s:exist}). This sets the stage for section \ref{ss:random1}
where we propose a new method, i.e.\ the random scale detection function.
We discuss three different formulations of the likelihood for this
function of which two should produce unbiased estimates of abundance,
while the third only delivers unbiased estimates under certain conditions
(section \ref{s:likelihoods}). We expand the random scale to a mixed
scale model (section \ref{s:mixed}), demonstrate our proposed methods
in a simulation study (section \ref{s:modelfitcode}) and apply the
mixed effect approach to harbor porpoise detections in comparison
to the equivalent fixed effect approach (section \ref{sec:Application-to-harbor}).


\section{Existing methods for fitting flexible detection functions}

\label{s:exist} Currently there are three primary ways to fit detection
functions for distance sampling data. The most common is the key function
and adjustment series described in \citet{Buckland2001}. The general
formula is:

\[
g(x)=\frac{k(x)(1+\sum_{j=1}^{m}a_{j}p_{j}(x))}{k(0)(1+\sum_{j=1}^{m}a_{j}p_{j}(0))}
\]


\noindent where $k(x)$ is a key function, $p_{j}(x)$ is a series
of adjustment functions with coefficients $a_{j}$ and \textit{m}
the total number of adjustment terms fitted. The denominator scales
the function such that $g(0)$=1 although it is not necessary for
fitting because the denominator cancels in eq \ref{eq:lt pdf}. An
example is a half-normal key function and a cosine adjustment series

\[
g(x)=\frac{\exp(-(x/\gamma)^{2}/2)(1+\sum_{j=1}^{m}a_{j}\cos(j\pi x/w))}{(1+\sum_{j=1}^{m}a_{j})}
\]


\noindent where $\gamma$ is the scale parameter of the half-normal
key function. This key-adjustment approach allows for flexible fitting
to the observed distances. It does, however, require defining a truncation
width (\textit{w}), imposing non-linear constraints to maintain monotonicity
(i.e.\ $g(x_{1})\geq g(x_{2})$ for all $w\geq x_{2}>x_{1}$) and
ensuring that $1\geq g(x)>0$. In addition, it has been shown that
fitting of detection functions with long tails is problematic with
this approach.

A second approach is to include explanatory covariates (\textbf{\textit{z}})
in the scale parameter of the half-normal or hazard-rate detection
function \citep{Marques2003}. An example using a half-normal detection
function is:

\begin{equation}
g(\bm{x}|\bm{z})=\exp(-[\bm{x}/\exp(\bm{X_{z}\bm{\beta}})]^{2}/2)\label{eq:mcds}
\end{equation}


\noindent where \textbf{\textit{x}} is the vector of distances, \textbf{\textit{z}}
is a data vector or matrix (depending on how many covariates are included
in the model), $\bm{X_{z}}$ is a design matrix for the covariates
and $\bm{\beta}$ is a parameter vector. In comparison to the previous
approach, no adjustment series need be used and the single parameter
scale of the half-normal function (or the hazard-rate) is replaced
with \textit{$\exp(\bm{X_{z}\bm{\beta}})$}. Hence, the scale of the
detection function is adjusted for each detected object depending
on the observed covariate values during the detection. Larger scales
generally relate to higher detection probabilities at distances $x>0$
compared to smaller scales.

The model in eq \ref{eq:mcds} is conditional on \textbf{\textit{z}};
hence, it is essential that the unspecified distribution for \textbf{\textit{z}}
is independent of \textbf{\textit{x}}. An obvious example where this
fails is animal behavior that might differ with \textbf{\textit{x}}
(e.g.\ responsive movement of the animals to the observer). This
approach provides monotone detection functions without constraints,
does not require truncation and is suitable for fitting long tails.
It has the added advantage of providing better small-area estimates
of density when the covariates vary spatially \citep{Hedley2004}.
On the other hand, the covariate approach does depend on being able
to identify and measure covariates that affect detection probability
\citep{Marques2003,Marques2007}.

If there is any remaining lack of fit, the first and second approaches
can be combined using covariates in the key function and a series
adjustment \citep[e.g.][]{Marques2007}. However, it is then fraught
with the same problems as the first approach where the constraints
may become even more problematic as they depend on the explanatory
covariate values. Even if the function is constrained correctly for
all observed values of \textbf{\textit{z}}, predictions for unobserved
values of \textbf{\textit{z}} may yield invalid probabilities due
to the addition of adjustment functions.

The third approach is rather recent and involves fitting a mixture
of \textit{m} detection functions (\citeyear{Miller}, in prep) along
the lines of \citet{Pledger2000} for capture-recapture models. Here,
the detection function can be represented as:

\[
g(x)=\sum_{j=1}^{m}\pi_{j}g_{j}'(x)
\]


\noindent where $\sum_{j=1}^{m}\pi_{j}=1$ and $g_{j}'(x)$ is a properly
specified detection function. As long as each component detection
function is monotone, $g(x)$ will be monotone.


\section{Random and mixed scale detection functions}

\label{s:random} 


\subsection{Random scale detection function}

\label{ss:random1} An additional approach we present here is to use
random effects in the detection function scale to allow for unmodeled
heterogeneity in detection. Consider a half-normal detection function
where the scale parameter is modeled with an intercept $\beta$ and
a normal error term $\epsilon$ for each detection with mean zero
and unknown standard deviation (\textit{$\epsilon\sim N\left(0,\sigma_{\epsilon}\right)$}):

\begin{equation}
g(x|\epsilon)=\exp(-x^{2}/(2\gamma(\epsilon)^{2}))\quad.\label{eq:ran gx}
\end{equation}


\noindent The scale is now modeled as:

\[
\gamma(\epsilon)=\exp(\beta+\epsilon)\quad.
\]


\noindent We assume a normal distribution for $\epsilon$ and use
$N(\epsilon,0,\sigma_{\epsilon})=\exp\left(-0.5\left(\frac{\epsilon}{\sigma_{\epsilon}}\right)^{2}\right)\left(\sqrt{2\pi}\sigma_{\epsilon}\right)^{-1}$
as shorthand for the normal density function evaluated at $\epsilon$
with mean zero and standard deviation $\sigma_{\epsilon}$. Considering
that long-tails may result from some objects with high detection probabilities
out to great distances or some conditions under which objects are
detectable at great distances, it is clear that this random scale
will be able to cope with long-tailed detection functions (i.e.\ with
large values for $\epsilon$).


\subsection{Likelihood formulations for the random scale detection function}

\label{s:likelihoods}

Using the random scale detection function, the marginalized likelihood
for the sample of \textit{n} observed distances can be derived directly
from equations 2.39 and 2.40 in \citet{Borchers2004}. In comparison
with the covariate approach using fixed effects from above, we think
of the random effect as a covariate with unknown values and integrate
over the random effect. This is accomplished by including an integral
over the unknown random effect in both the numerator and denominator:

\begin{equation}
L_{g}(\beta,\sigma_{\epsilon})=\prod_{i=1}^{n}\frac{\intop_{-\infty}^{\infty}g(x_{i}|\epsilon)\, N(\epsilon,0,\sigma_{\epsilon})d\epsilon}{\intop_{-\infty}^{\infty}\int_{0}^{w}g(u|\epsilon)du\, N(\epsilon,0,\sigma_{\epsilon})d\epsilon}\label{eq:g likelihood}
\end{equation}


\noindent where the $x_{i}$ refer to the distances to the detected
objects with \textit{$i=1,2,...,n$}. We denote \textit{$L_{g}$}
with subscript \textit{g} indicating that here we use a properly defined
detection function \textit{$g(x|\epsilon)$} with \textit{$g(0)=1$}
(for comparison see \textit{$L_{f}$} below). Also, in this formulation
the scale intercept is denoted with \textit{$\beta_{g}$}. The numerator
of eq \ref{eq:g likelihood} is the marginal probability that the
\textit{i}th object was seen at \textit{$x_{i}$}:

\begin{equation}
\intop_{-\infty}^{\infty}g(x_{i}|\epsilon)N(\epsilon,0,\sigma_{\epsilon})\frac{1}{w}d\epsilon\quad,\label{eq:num random}
\end{equation}


\noindent while the denominator of eq \ref{eq:g likelihood} is the
marginal probability that the object was seen within truncation width
\textit{w}:

\begin{equation}
\intop_{-\infty}^{\infty}\int_{0}^{w}g(u|\epsilon)du\, N(\epsilon,0,\sigma_{\epsilon})\frac{1}{w}d\epsilon\quad.\label{eq:p random}
\end{equation}


\noindent We note that in contrast to point transects, the availability
function for line transects $h(x)=1/w$ from eqs \ref{eq:num random}
and \ref{eq:p random} cancel in eq \ref{eq:g likelihood}.

An alternative likelihood is:

\begin{equation}
L_{f}(\beta,\sigma_{\epsilon})=\prod_{i=1}^{n}\frac{\intop_{-\infty}^{\infty}f(x_{i}|\epsilon)\, N(\epsilon,0,\sigma_{\epsilon})d\epsilon}{\intop_{-\infty}^{\infty}\int_{0}^{w}f(u|\epsilon)du\, N(\epsilon,0,\sigma_{\epsilon})d\epsilon}\label{eq:f likelihood}
\end{equation}


\noindent where

\noindent 
\[
f(x|\epsilon)=2\left(\sqrt{2\pi}\gamma(\epsilon)\right)^{-1}\exp\left(-x^{2}/(2\gamma(\epsilon)^{2})\right),\quad\quad x\geq0
\]
is the pdf in absence of truncation ($w=\infty).$

We now emphasize why and how $L_{g}$ and $L_{f}$ differ. It is tempting
to think that they are based on the same model because the half-normal
shapes of $g(x|\epsilon)$ and $f(x|\epsilon)$ formally satisfy the
standard relationship eq 1. However, eq \ref{eq:lt pdf} applies only
to the marginal $g$ and $f$, and not to the individual level quantities
$g(x|\epsilon)$ and $f(x|\epsilon)$ for each object. In fact, as
$g(x|\epsilon)=\left(\sqrt{\pi/2}\gamma(\epsilon)\right)f(x|\epsilon)$,
we have 
\[
L_{g}(\beta,\sigma_{\epsilon})=\prod_{i=1}^{n}\frac{\intop_{-\infty}^{\infty}\gamma(\epsilon)f(x_{i}|\epsilon)\, N(\epsilon,0,\sigma_{\epsilon})d\epsilon}{\intop_{-\infty}^{\infty}\int_{0}^{w}\gamma(\epsilon)f(u|\epsilon)du\, N(\epsilon,0,\sigma_{\epsilon})d\epsilon},
\]
which makes it explicit that the marginalization ``over the half-normal
shape'', may it be $g$ or $f$, is done differently in the two respective
likelihoods $L_{g}$ and $L_{f}$. The reason for the difference is
that the value of $\epsilon$ affects the detection probability of
an individual object, as for any object at distances larger than zero,
increasing $\epsilon$ increases the probability of detection $g(x|\epsilon)$.
This, in turn, creates a selection bias at any given distance larger
than zero towards those objects with the higher values for $\epsilon$.
The following paragraph, which is proved in the appendix, shows that
this is indeed true and that it is possible to quantify this selection
bias.

If the probability density of $\epsilon$ in the full population is
$N(\epsilon,0,\sigma_{\epsilon})$ (the $g$ case), then it may be
proved that the probability density among the detected animals is
proportional to $\gamma(\varepsilon)N(\epsilon,0,\sigma_{\epsilon})\propto N(\epsilon,\sigma_{\epsilon}^{2},\sigma_{\epsilon})$.
That is, the density among the detected animals is still Gaussian,
but has been shifted to the right by an amount $\sigma_{\epsilon}^{2}$.
This also shifts the distribution of $\gamma(\varepsilon)=\exp(\beta+\varepsilon)$
towards the right, and hence confirms our intuition about the direction
of the selection bias. Under the likelihood $L_{f}$, on the other
hand, it is assumed that the density of $\epsilon$ among the detected
animals is $N(\epsilon,0,\sigma_{\epsilon})$, i.e.\
ignoring the right-shift. This will affect the estimate of $\beta,$
and as shown in the appendix, the estimate of $\beta$ obtained from
$L_{f}$ is 
\begin{equation}
\beta_{f}=\beta_{g}+\sigma_{\epsilon}^{2},\label{eq:beta =00003D beta + sigma}
\end{equation}
where $\beta_{g}$ is obtained from $L_{g}$. 

One might be tempted to use the following likelihood:

\begin{equation}
L_{f1}(\beta,\sigma_{\epsilon})=\prod_{i=1}^{n}\intop_{-\infty}^{\infty}\frac{g(x_{i}|\epsilon)}{\intop_{0}^{w}g(u|\epsilon)du}N(\epsilon,0,\sigma_{\epsilon})d\epsilon\quad.\label{eq:Incorrect likelihood}
\end{equation}


\noindent Compared to eq \ref{eq:g likelihood}, the normal density
is omitted from the denominator and the random effect is integrated
out simultaneously over the numerator and denominator. But this is
not correct and will produce biased estimates. If $w=\infty$, then
the relationship $\beta_{f1}=\beta_{g}+\sigma_{\epsilon}^{2}$ holds
where $\beta_{f1}$ is derived from eq \ref{eq:Incorrect likelihood}.
However, it does not hold if the data are truncated as is generally
the case for wildlife studies.


\subsection{Mixed scale detection function}

\label{s:mixed} A mixed effects model in which observed covariates
($\bm{z}$) are included in the detection function can be accomplished
by combining the covariate model from above (eq \ref{eq:mcds}) with
the random scale model (eq \ref{eq:ran gx}) using:

\begin{equation}
\gamma(\bm{\epsilon},\bm{z})=\exp(\bm{X_{z}}\bm{\beta}+\bm{\epsilon})\quad.\label{eq:lognormal_gamma}
\end{equation}

\noindent where $\bm{X_{z}}$ is a design matrix for
the observed covariate values, $\bm{\beta}$ is a parameter vector
and \textit{$\bm{\epsilon}$} is the vector of \textit{n} errors associated
with the detections. Note that here the intercept \textit{$\beta$}
from eq \ref{eq:ran gx} is replaced with \textit{$\bm{X_{z}\beta}$}.
The half-normal detection function with a mixed scale can now be written
as:

\begin{equation}
g(\bm{x}|\bm{z},\bm{\epsilon})=\exp(-[\bm{x}/\exp(\bm{X_{z}\bm{\beta}}+\bm{\epsilon})]^{2}/2)\label{eq:mixed gx}
\end{equation}


In this case, the likelihood is conditional on the observed covariate
values. Using the \textit{g} formulation equivalent to eq \ref{eq:g likelihood},
the likelihood for the sample of \textit{n} observations is now given
by:

\begin{equation}
L_{g}(\bm{\beta},\sigma_{\epsilon}|\bm{z})=\prod_{i=1}^{n}\frac{\intop_{-\infty}^{\infty}g(x_{i}|\bm{z},\epsilon)\, N(\epsilon,0,\sigma_{\epsilon})d\epsilon}{\intop_{-\infty}^{\infty}\int_{0}^{w}g(u|\bm{z},\epsilon)du\, N(\epsilon,0,\sigma_{\epsilon})d\epsilon}\label{eq:rangz likelihood}
\end{equation}



\subsection{Density estimators using a random or mixed scale}

Using a random scale detection function, object density \textit{D}
can be obtained using eq \ref{eq:p random} in place of \textit{p}
in eq \ref{eq:density} giving:

\[
D=\frac{n}{2wL\intop_{-\infty}^{\infty}\int_{0}^{w}g(u|\epsilon)du\, N(\epsilon,0,\sigma_{\epsilon})\frac{1}{w}d\epsilon}\quad.
\]


When explanatory covariates are included for the mixed scale approach,
the Horvitz-Thompson-like estimator (eq 2.44 in \citealp{Borchers2004})
can be used to estimate object density:

\begin{equation}
D=\sum_{i=1}^{n}\frac{1}{2wLp_{i}}=\sum_{i=1}^{n}\frac{1}{2wL\intop_{-\infty}^{\infty}\int_{0}^{w}g(u|\epsilon,z_{i})du\, N(\epsilon,0,\sigma_{\epsilon})\frac{1}{w}d\epsilon}\quad,\label{eq:density-1}
\end{equation}


\noindent where for each of \textit{$i=1,2,...,n$} objects, $1$
is divided by the probability that it is detected $p_{i}$, which
are then summed up over all \textit{n}. For the mixed scale approach,
the denonminator of eq \ref{eq:density-1} needs to be replaced with
$s_{i}$, the size of the $i$th object, in the case that cluster
sizes are larger than 1 and density of individuals is estimated. 


\section{Comparing the likelihood functions via simulation}

\label{s:modelfitcode} R code for fitting models using maximum likelihood
with likelihood eqs \ref{eq:g likelihood} and \ref{eq:Incorrect likelihood},
to plot the fitted model and to compute abundance in the covered area
using eq \ref{eq:density-1} multiplied by 2\textit{wL} is provided
in the package \textit{RandomScale} (\url{https://github.com/jlaake/RandomScale}).
The \textit{RandomScale} package also contains TPL files that were
developed to fit the models with ADMB \citep{Fournier2012} using
each of the likelihoods (eqs \ref{eq:g likelihood}, \ref{eq:f likelihood},
and \ref{eq:Incorrect likelihood}). In addition, C++ code was written
to enable the use of multinomial weights with Gauss-Hermite integration
for the random effects and is contained in the package. This section
serves to illustrate the results obtained with the three different
likelihood formulations described above. All of the code used in this
manuscript is explained in detail in Appendices \ref{sub:Model-fitting-code}
and \ref{sub:Fitting-mixed-scale} as well as provided as demo code
with the package. 


\subsection{Fitting random scale detection functions}

We simulate \textit{n} detections from a half-normal detection function
with the default value for $\beta_{g}$ = 2 and without any truncation
(i.e.\ \textit{w} = $\infty$). We then fit models to these data
with the R code from the \textit{RandomScale} package using likelihood
eqs \ref{eq:g likelihood} and \ref{eq:Incorrect likelihood}. We
show plots for each including one with the adjustment of $\beta_{f1}=\beta_{g}+\sigma_{\epsilon}^{2}$
for eq \ref{eq:Incorrect likelihood} (when using eq \ref{eq:Incorrect likelihood},
the \textit{intercept parameter} is $\beta_{f1}$). Figure \ref{fig:graph003}
and Table \ref{tab:Comparison_table} demonstrate that eq \ref{eq:Incorrect likelihood}
produces results that are nearly identical to eq \ref{eq:g likelihood}
when the data are not truncated and $\beta_{f1}$ is adjusted.

<<results=hide,echo=FALSE>>=
pdf("RcodeFitting.pdf",width=6,height=4)
par(mfrow=c(1,3)) 
@
<<results=hide,echo=FALSE>>=
# simulate data
x=simdata(n=500,w=Inf,beta=2,beta_eps=-.5)
# fit data with g likelihood; beta_eps is starting value
results_random=fitdata(x,w=Inf)
plotfit(x,w=max(x),results_random$model$par,nclass=30,
        main="eq 6 likelihood",adjust=FALSE)
# fit data with incorrect likelihood
results_random_wrong=fitdata(x,w=Inf,wrong=TRUE)
plotfit(x,w=max(x),results_random_wrong$model$par,nclass=30,
        main="eq 11 likelihood",adjust=FALSE)
plotfit(x,w=max(x),results_random_wrong$model$par,nclass=30,
       main="eq 11 likelihood\nadjusted beta")
@
<<results=hide,echo=FALSE>>=
dev.off()
@
\begin{figure}[h]
\includegraphics[width=6in,height=4in]{RCodeFitting.pdf}
\caption{\label{fig:graph003}Random scale detection functions fitted to simulated
data with R code using the likelihood eqs \ref{eq:g likelihood} and
\ref{eq:Incorrect likelihood}. }
\end{figure}

Using the same data, we use calls to ADMB from the \textit{RandomScale}
package to fit models using likelihood eqs \ref{eq:g likelihood},
\ref{eq:f likelihood}, and \ref{eq:Incorrect likelihood} and plot
the fitted models with the appropriate adjustments to $\beta_{f}$
and $\beta_{f1}$. Figure \ref{fig:graph004} demonstrates that when
the data are not truncated the three likelihood equations fit similar
detection functions. For this example of untruncated data, results
from the R code and ADMB are nearly identical (Table \ref{tab:Comparison_table}). 

<<results=hide,echo=FALSE>>=
pdf("ADMBcodeFitting.pdf",width=6,height=4)
par(mfrow=c(1,3)) 
@

<<results=hide,echo=FALSE>>=
glike=fitadmb(x,w=Inf,likelihood="g",verbose=FALSE)
plotfit(x,w=Inf, glike$coefficients[1:2],nclass=30,
                 main="eq 6 likelihood",adjust=FALSE)
f2like=fitadmb(x,w=Inf,likelihood="f2",verbose=FALSE)
plotfit(x,w=Inf,f2like$coefficients[1:2],nclass=30,
                 main="eq 9 likelihood\nadjusted beta")
f1like=fitadmb(x,w=Inf,likelihood="f1",verbose=FALSE)
plotfit(x,w=Inf,f1like$coefficients[1:2],nclass=30,
                 main="eq 11 likelihood\nadjusted beta")
@


<<results=hide,echo=FALSE>>=
dev.off()
@

\begin{figure}[h]
\includegraphics[width=6in,height=4in]
{ADMBcodeFitting.pdf} \caption{\label{fig:graph004} Random scale detection functions fitted to simulated
data with ADMB code using the likelihood eqs \ref{eq:g likelihood},
\ref{eq:f likelihood} and \ref{eq:Incorrect likelihood}.}
\end{figure}

\begin{table}[h]
\caption{\label{tab:Comparison_table}Comparison of random scale model fitting
results from R and ADMB using simulated data. True values for $\beta_{g}$
and $log(\sigma_{\epsilon})$ were 2 and -0.5.}


\begin{tabular}{cccccc}
\hline 
Code  & Likelihood eq  & Log-likelihood  & $\beta_{f}$  & $\beta_{g}$  & log($\sigma_{\epsilon}$)\tabularnewline
\hline 
R  & eq \ref{eq:g likelihood}  & \Sexpr{sprintf("%7.2f",-results_random$model$val)} & NA  & \Sexpr{ sprintf("%5.3f",results_random$model$par[1])} & \Sexpr{sprintf("%5.3f",results_random$model$par[2])}\tabularnewline
R  & eq \ref{eq:Incorrect likelihood}  & \Sexpr{sprintf("%7.2f",-results_random_wrong$model$val)} & \Sexpr{sprintf("%5.3f",results_random_wrong$model$par[1])} & \Sexpr{sprintf("%5.3f",results_random_wrong$model$par[1]-exp(results_random_wrong$model$par[2]*2))} & \Sexpr{sprintf("%5.3f",results_random_wrong$model$par[2])}\tabularnewline
ADMB  & eq \ref{eq:g likelihood}  & \Sexpr{sprintf("%7.2f",glike$loglik)} & NA  & \Sexpr{sprintf("%5.3f",glike$coeflist[[1]])} & \Sexpr{sprintf("%5.3f",glike$coeflist[[2]])}\tabularnewline
ADMB  & eq \ref{eq:f likelihood}  & \Sexpr{sprintf("%7.2f",f2like$loglik)} & \Sexpr{sprintf("%5.3f",f2like$coeflist[[1]])} & \Sexpr{sprintf("%5.3f",f2like$coeflist[[1]]-exp(2*f2like$coeflist[[2]]))} & \Sexpr{sprintf("%5.3f",f2like$coeflist[[2]])}\tabularnewline
ADMB  & eq \ref{eq:Incorrect likelihood}  & \Sexpr{sprintf("%7.2f",f1like$loglik)} &  \Sexpr{sprintf("%5.3f",f1like$coeflist[[1]])} &  \Sexpr{sprintf("%5.3f",f1like$coeflist[[1]]-exp(2*f2like$coeflist[[2]]))} & \Sexpr{sprintf("%5.3f",f1like$coeflist[[2]])}\tabularnewline
\hline 
\end{tabular}
\end{table}


\subsection{Fitting mixed scale detection functions}

The following is an example of a mixed effects model that can only
be fitted at present with the ADMB code and the $L_{f}$ likelihood
from eq \ref{eq:f likelihood}. We simulate 3000 objects from a half-normal
detection function truncated at \textit{w} = 50 with a random scale
where the first 2000 detected objects were generated using a larger
scale intercept $\beta_{g}$ compared to the last 1000 objects. The
subsects of the data are distinguished by including a two-level factor
covariate with values 0 and 1 for the first and second subset, respectively.
All objects have the same random effect distribution. We fit two models
to the data, both using the likelihood $L_{f}$ from eq \ref{eq:f likelihood},
however, one model with the covariate (mixed scale) and one without
the covariate (random scale). 

<<results=hide,echo=FALSE>>=
pdf("ADMBWithandWithoutCovariate.pdf",width=6,height=4)
par(mfrow=c(1,2))
@

<<results=hide,echo=FALSE>>=
# simulate data
x1=simdata(n=2000,w=50,beta_eps=-.5,beta=2,
          fixed=FALSE,reject=TRUE)
x2=simdata(n=1000,w=50,beta_eps=-.5,beta=1,
          fixed=FALSE,reject=TRUE)
df=data.frame(covariate=c(rep(0,length(x1)),
          rep(1,length(x2))),distance=c(x1,x2))
# fit data with covariate
fwlike=fitadmb(df,w=50,formula=~covariate,
               likelihood="f2",verbose=FALSE)
param=fwlike$coefficients[1:3]
Nhatwcov=plotfit(df$distance,w=50,par=param,nclass=30,
                 dm=model.matrix(~covariate,df),
                 main="With covariate")
Nhatwcov.se=compute_Nhat.se(par=param,fwlike$vcov[1:3,1:3],
                 x=df,w=50,dm=model.matrix(~covariate,df))
# fit data without covariate
flike=fitadmb(df,w=50,formula=~1,
              likelihood="f2",verbose=FALSE)
param=flike$coefficients[1:2]
Nhatwocov=plotfit(df$distance,w=50,par=param,nclass=30,
                 main="Without covariate")
Nhatwocov.se=compute_Nhat.se(par=param,flike$vcov[1:2,1:2],
                 x=df,w=50,dm=model.matrix(~1,df))
@


<<results=hide,echo=FALSE>>=
dev.off()
@

\noindent The fit of the detection functions averaged over all data
look similar for both models (Figure \ref{fig:graph005}) but the
model with the covariate is clearly better with a $\triangle$AIC
of \Sexpr{round(-2*flike$loglik+2*2-(-2*fwlike$loglik+2*3),2)}. The
estimate of abundance from the model with the covariate is \Sexpr{round(Nhatwcov,0)}
(se=\Sexpr{round(Nhatwcov.se,1)}) and without the covariate is \Sexpr{round(Nhatwocov,0)}
(se=\Sexpr{round(Nhatwocov.se,1)}). For the mixed effect model the
estimated standard deviation (\Sexpr{round(exp(fwlike$coefficients[3]),2)})
is smaller than the same quantity for the random effect model (\Sexpr{round(exp(flike$coefficients[2]),2)})
which absorbs the heterogeneity due to the missing covariate into
the random effect.

\begin{figure}[h]
\includegraphics[width=6in,height=4in]
{ADMBWithandWithoutCovariate.pdf}\caption{\label{fig:graph005} Average detection functions fitted to simulated
data with ADMB code using the likelihood eq \ref{eq:f likelihood}
with and without the covariate. }
\end{figure}

<<echo=FALSE,results=hide>>=
pdf("ADMBByCovariate.pdf",width=6,height=4)
par(mfrow=c(2,2))
param=fwlike$coefficients[1:3]
Nhatwcov0=plotfit(df$distance[df$covariate==0],w=50,par=param,
            nclass=30,dm=model.matrix(~covariate,df[df$covariate==0,]),
            main="With covariate value=0")
Nhatwcov0.se=compute_Nhat.se(par=param,fwlike$vcov[1:3,1:3],
                 x=df[df$covariate==0,],w=50,
                dm=model.matrix(~covariate,df[df$covariate==0,]))
Nhatwcov1=plotfit(df$distance[df$covariate==1],w=50,par=param,
             nclass=30,dm=model.matrix(~covariate,df[df$covariate==1,]),
             main="With covariate value=1")
Nhatwcov1.se=compute_Nhat.se(par=param,fwlike$vcov[1:3,1:3],
                x=df[df$covariate==1,],w=50,
                dm=model.matrix(~covariate,df[df$covariate==1,]))
param=flike$coefficients[1:2]
Nhatwocov0=plotfit(df$distance[df$covariate==0],w=50,par=param,
             nclass=30, main="Without covariate value=0")
Nhatwocov0.se=compute_Nhat.se(par=param,flike$vcov[1:2,1:2],
                 x=df[df$covariate==0,],w=50,
                dm=model.matrix(~1,df[df$covariate==0,]))
Nhatwocov1=plotfit(df$distance[df$covariate==1],w=50,par=param,
             nclass=30,main="Without covariate value=1")
Nhatwocov1.se=compute_Nhat.se(par=param,flike$vcov[1:2,1:2],
                 x=df[df$covariate==1,],w=50,
                dm=model.matrix(~1,df[df$covariate==1,]))
dev.off()
@

The total abundance estimates are similar, but when abundance is estimated
for each type of object (with covariate: \Sexpr{round(Nhatwcov0,0)}
(se = \Sexpr{round(Nhatwcov0.se,1)}) and \Sexpr{round(Nhatwcov1,1)}
(se = \Sexpr{round(Nhatwcov1.se,1)}); without covariate: \Sexpr{round(Nhatwocov0,0)}
(se = \Sexpr{round(Nhatwocov0.se,1)}) and  \Sexpr{round(Nhatwocov1,1)}
(se = \Sexpr{round(Nhatwocov1.se,1)}) the importance of including
the covariate becomes obvious. When using the model with the covariate,
the model fits tighter to the observed data (Figure \ref{fig:graph006})
in particular for the subset of the data with the smaller sample size,
i.e.\ the subsect of the data with covariate value
= 1. On the other hand, for the model without the covariate predicted
detection probabilities are too low for distances near zero and too
high for larger distances which results in an underestimate of abundance
of those with covariate value 1. Likewise, the estimated abundance
for objects with covariate value 0 is too high. 

\begin{figure}[h]
\includegraphics[width=6in,height=4in]
{ADMBByCovariate.pdf}\caption{\label{fig:graph006} Detection functions fitted to simulated data
with ADMB code using the likelihood eq \ref{eq:f likelihood} with
(top row of plots) and without the covariate (bottom row of plots)
shown for subsets x1 and x2 of the simulated data. }
\end{figure}

\section{\label{sec:Application-to-harbor}Application to harbor porpoise
data}

<<echo=FALSE,results=hide>>=
pdf("hp.pdf",width=6,height=6)
par(mfrow=c(1,2))
hp=read.delim("hp.txt",header=TRUE)
library(mrds)

modmcds=ddf(dsmodel=~cds(key="hn",formula=~size),data=hp,method="ds")
xx=summary(modmcds)
xx
modmixed=fitadmb(hp,formula=~size,w=443.1635)
summary(modmixed)
Nhat.mcds=xx$Nhat
Nhat.se.mcds=xx$Nhat.se
par(mfrow=c(2,1))
plotfit(hp$distance,w=443.1635,dm=model.matrix(~size,hp[,"size",drop=FALSE]),par=modmixed$coeff[1:3])
plot(modmcds,new=FALSE,showpoints=FALSE,pl.den=0,main="")

Nhat.mixed=compute_Nhat(par=modmixed$coeff[1:3],x=hp$distance,w=443.1635,dm=model.matrix(~size,hp[,"size",drop=FALSE]))
Nhat.se.mixed=compute_Nhat.se(par=modmixed$coeff[1:3],vcov=modmixed$vcov[1:3,1:3],x=hp$distance,w=443.1635,dm=model.matrix(~size,hp[,"size",drop=FALSE]))

Nhat.mcds
Nhat.se.mcds
Nhat.mixed
Nhat.se.mixed

dev.off()
@

In 2002, a small boat survey for harbor porpoise (\textit{Phocoena
phocoena}) was conducted in waters of the Strait of Juan de Fuca and
around the San Juan Islands in Washington state, USA. Three observers
surveyed along a set of systematically placed lines with an observer
standing on the bow and at the starboard and port sides. When harbor
porpoise were detected, the angle from the line to the harbor porpoise
was measured with an angle board and the radial distance to the detection
was estimated visually. Observers were trained and tested in visual
distance estimation but for this example, we ignore the error in distance
estimation. The angle and radial distance was converted to perpendicular
distance. In addition to distance, the number of harbor porpoise (size)
was recorded for each detection. 

A total of \Sexpr{nrow(hp)} harbor porpoise groups were detected
with group size varying from 1 to \Sexpr{max(hp$size)}. We fitted
a model with a half-normal detection function and used group size
as a covariate. We fitted a fixed effect detection function with the
\textit{mrds} package (\citealt{mrds2013}) and a mixed effects detection
function with the \textit{RandomScale} package. The \textit{mrds} package requires
a finite width, so to make the AIC values equivalent we set $w$=443.2
the largest distance for each analysis. The fit of the detection functions
(Table \ref{tab:hp example_table}) look similar (Figure \ref{fig:graph007})
but the model that includes the random effect is slightly better with
a $\triangle$AIC of \Sexpr{ formatC(xx$aic-(-2*modmixed$loglik+2*modmixed$npar),digits=2)}.
The estimate of abundance within the 886.4 meter strip is \Sexpr{paste(formatC(Nhat.mcds,digits=4)," (se = ",formatC(Nhat.se.mcds,digits=2),")",sep="")}
for the fixed effect model and \Sexpr{paste(formatC(Nhat.mixed,digits=4)," (se = ",formatC(Nhat.se.mixed,digits=2),")",sep="")}
for the mixed effect model. The higher abundance estimate resulted
from the slightly steeper estimated detection function (Figure \ref{fig:graph007}). 

\begin{figure}[h]
\includegraphics[width=6in,height=4in]
{hp.pdf}\caption{\label{fig:graph007} Detection functions fitted to harbor porpoise
vessel survey data. The upper panel is the mixed effects model and
lower panel is the fixed effects model. Both include group size as
a covariate. }
\end{figure}

\begin{table}[h]
\caption{\label{tab:hp example_table}Parameter estimates, standard errors
for fixed (AIC=\Sexpr{sprintf("%5.1f",xx$aic)}) and mixed effect
(AIC=\Sexpr{sprintf("%5.1f",-2*modmixed$loglik+2*modmixed$npar)})
models fitted to harbor porpoise vessel survey data. }


\begin{tabular}{ccccc}
\hline 
 & \multicolumn{2}{c}{Fixed-effect} & \multicolumn{2}{c}{Mixed-effect}\tabularnewline
\hline 
 & Estimate & Std error & Estimate & Std error\tabularnewline
\cline{2-5} 
Intercept &  \Sexpr{sprintf("%5.3f", xx$coeff$key.scale$estimate[1] )} &  \Sexpr{sprintf("%5.3f", xx$coeff$key.scale$se[1] )} &  \Sexpr{sprintf("%5.3f", coef(modmixed)[1] )} &  \Sexpr{sprintf("%5.3f", summary(modmixed)$coefficients[1,2] )}\tabularnewline
Size &  \Sexpr{sprintf("%5.3f", xx$coeff$key.scale$estimate[2] )} &  \Sexpr{sprintf("%5.3f", xx$coeff$key.scale$se[2] )} &  \Sexpr{sprintf("%5.3f", coef(modmixed)[2] )} &  \Sexpr{sprintf("%5.3f", summary(modmixed)$coefficients[2,2] )}\tabularnewline
log($\sigma_{\epsilon}$) &  &  &  \Sexpr{sprintf("%5.3f", coef(modmixed)[3] )} &  \Sexpr{sprintf("%5.3f", summary(modmixed)$coefficients[3,2] )}\tabularnewline
\hline 
\end{tabular}
\end{table}

\section{Discussion}

Incorporating a random effect in the scale of the detection function
extends the covariate approach of \citet{Marques2003} to enable modeling
of additional unspecified and typically unknown sources of heterogeneity
in detection probability. This removes the need to select an arbitrary
truncation width which is typically needed for the CDS key-adjustment
function fitting \citep{Buckland2001}. The random and mixed effects
modeling can be used with other detection functions such as the hazard
function \citep{Buckland2001} as long as the parametrization includes
a scale parameter ($x/\sigma)$; although it could also be applied
to the shape parameter in the hazard function. The models can be easily
extended to allow covariates to be included for the random effects
standard deviation $\sigma_{\epsilon}$. For example, heterogeneity
in detection probability may be enhanced or reduced as a function
of weather, habitat or other covariates. We propose that a random
or mixed effect model of the detection function scale be adopted as
a standard approach for fitting detection functions in distance sampling. 


\section*{Acknowledgements}

We thank Steve Buckland for reviewing a nearly final draft of the
paper. The first author was supported by a studentship jointly funded
by the University of St Andrews and EP-SRC, through the National Centre
for Statistical Ecology (EPSRC grant EP/C522702/1).

\bibliographystyle{biom}
\bibliography{biblio}



\section{Appendix}


\subsection{Connection between the f and g formulations}

\noindent The result referred to above in eq \ref{eq:beta =00003D beta + sigma}
section \ref{s:likelihoods} applies to the situation where the detection
function is of the form $g(x|\gamma)=k(x/\gamma)$, where $k()$ is
some base detection function and $\gamma>0$ is a scale parameter.
Under this model the perpendicular density for line transects is $f(x|\gamma)=\left\{ \int_{0}^{\infty}g(x|\gamma)dx\right\} ^{-1}g(x|\gamma)=\gamma^{-1}\left\{ \int_{0}^{\infty}k(u)du\right\} ^{-1}k(x/\gamma)$.
The second requirement for the result to hold is that the scale parameter
$\gamma$ has a log-normal distribution given by eq \ref{eq:lognormal_gamma}.
For simplicity we ignore the regression part in eq \ref{eq:lognormal_gamma}
such that $\gamma(\epsilon)=\exp(\epsilon)$, where $\epsilon\sim N(\beta,\sigma_{\epsilon})$.

Consider two sampling mechanisms: 
\begin{enumerate}
\item Each individual in the population (whether detected or not) has detection
function $g\left\{ x|\gamma(\epsilon)\right\} $, where $\epsilon\sim N(\beta,\sigma_{\epsilon})$.
This gives rise to the likelihood in eq \ref{eq:g likelihood}. 
\item Each individual \textit{among the detected individuals} has perpendicular
density $f\left\{ x|\gamma(\epsilon)\right\} $, where $\epsilon\sim N(\beta,\sigma_{\epsilon})$.
This gives rise to the likelihood in eq \ref{eq:f likelihood}. 
\end{enumerate}
The difference between the two is the subgroup to which the assumption
about lognormality is applied. The following result shows that likelihoods
are linked parametrically.


\paragraph{Theorem}

Let $p_{g}(x;\beta,\sigma_{\epsilon})$ and $p_{f}(x;\beta,\sigma_{\epsilon})$
refer to the density of perpendicular distances truncated to the interval
$[0,w]$ under sampling mechanisms 1) and 2) above, respectively.
We then have $p_{f}(x;\beta,\sigma_{\epsilon})=p_{g}(x;\beta-\sigma_{\epsilon}^{2},\sigma_{\epsilon})$,
and $\beta_{f}=\beta_{g}+\sigma_{\epsilon}^{2}$.


\paragraph{Proof}

We put $\gamma(\epsilon)=\exp(\epsilon)$, and get

\begin{eqnarray*}
p_{g}(x;\beta-\sigma_{\epsilon}^{2},\sigma_{\epsilon}^{2}) & = & \frac{\int g(x|\gamma(\epsilon))\, N(\epsilon,\beta-\sigma_{\epsilon}^{2},\sigma_{\epsilon})d\epsilon}{\int\int_{0}^{w}g(u|\gamma(\epsilon))du\, N(\epsilon,\beta-\sigma_{\epsilon}^{2},\sigma_{\epsilon})d\epsilon}\\
 & = & \frac{\int\gamma(\epsilon)^{-1}g(x|\gamma(\epsilon))\,\exp(\epsilon)N(\epsilon,\beta-\sigma_{\epsilon}^{2},\sigma_{\epsilon})d\epsilon}{\int\int_{0}^{w}\gamma(\epsilon)^{-1}g(u|\gamma(\epsilon))du\,\exp(\epsilon)N(\epsilon,\beta-\sigma_{\epsilon}^{2},\sigma_{\epsilon})d\epsilon}\\
 & = & \frac{\int\gamma(\epsilon)^{-1}g(x|\gamma(\epsilon))\, N(\epsilon,\beta,\sigma_{\epsilon})d\epsilon\,\exp(\beta-\frac{1}{2}\sigma_{\epsilon}^{2})}{\int\int_{0}^{w}\gamma(\epsilon)^{-1}g(u|\gamma(\epsilon))du\, N(\epsilon,\beta,\sigma_{\epsilon})d\epsilon\,\exp(\beta-\frac{1}{2}\sigma_{\epsilon}^{2})}\\
 & = & p_{f}(x,\beta,\sigma_{\epsilon})
\end{eqnarray*}



\subsection{\label{sub:Model-fitting-code}Model fitting code for random effects
models}

The following code simulates \textit{n} detections from a half-normal
detection function with the default value for $\beta_{g}$ = 2 and
without any truncation (i.e.\ \textit{w} = $\infty$). Note that
the value for $\sigma_{\epsilon}$ enters the function on the log-scale
using the argument \textit{$beta\_eps$} to avoid numerical issues.
We then fit models with the R code from the \textit{RandomScale} package
(\url{https://github.com/jlaake/RandomScale}) using likelihood eqs
\ref{eq:g likelihood} and \ref{eq:Incorrect likelihood}. Using the
R code, these likelihood functions are fitted with the \textit{fitdata}
function where the argument \textit{wrong} allows distinguishing between
likelihood $L_{g}$ from eq \ref{eq:g likelihood} (using the default
\textit{wrong = FALSE}) and likelihood $L_{fi}$ from eq \ref{eq:Incorrect likelihood}
(\textit{wrong = TRUE}). We show plots for each including one with
the adjustment of $\beta_{f1}=\beta_{g}+\sigma_{\epsilon}^{2}$ for
eq \ref{eq:Incorrect likelihood} (if \textit{wrong = TRUE}, the first
parameter value returned from \textit{fitdata} is $\beta_{f1}$).
Figure \ref{fig:graph003} and Table \ref{tab:Comparison_table} demonstrate
that eq \ref{eq:Incorrect likelihood} produces results that are nearly
identical to eq \ref{eq:g likelihood} when the data are not truncated
and $\beta_{f1}$ is adjusted.

<<eval=FALSE>>=
# simulate data
x=simdata(n=500,w=Inf,beta=2,beta_eps=-.5)
# fit data with g likelihood; beta_eps is starting value
results_random=fitdata(x,w=Inf)
plotfit(x,w=max(x),results_random$model$par,nclass=30,
        main="eq 6 likelihood",adjust=FALSE)
# fit data with incorrect likelihood
results_random_wrong=fitdata(x,w=Inf,wrong=TRUE)
plotfit(x,w=max(x),results_random_wrong$model$par,nclass=30,
        main="eq 11 likelihood",adjust=FALSE)
plotfit(x,w=max(x),results_random_wrong$model$par,nclass=30,
       main="eq 11 likelihood\nadjusted beta")
@

Using the same data, we use calls to ADMB from R using the \textit{RandomScale}
package to fit models using likelihood eqs \ref{eq:g likelihood},
\ref{eq:f likelihood}, and \ref{eq:Incorrect likelihood} and plot
the fitted models with the appropriate adjustments to $\beta_{f}$
and $\beta_{f1}$. Note that for the function \textit{fitadmb} the
argument \textit{likelihood} determines which likelihood is used for
the optimization where \textquotedbl{}g\textquotedbl{}, \textquotedbl{}f2\textquotedbl{}
and \textquotedbl{}f1\textquotedbl{} refer to eqs \ref{eq:g likelihood},
\ref{eq:f likelihood}, and \ref{eq:Incorrect likelihood}, respectively.
Figure \ref{fig:graph004} demonstrates that when the data are not
truncated the three likelihood equations fit similar detection functions.
For this example of untruncated data, results from the R code and
ADMB are nearly identical (Table \ref{tab:Comparison_table}). 

<<eval=FALSE>>=
glike=fitadmb(x,w=Inf,likelihood="g",verbose=FALSE)
plotfit(x,w=Inf, glike$coefficients[1:2],nclass=30,
                 main="eq 6 likelihood",adjust=FALSE)
f2like=fitadmb(x,w=Inf,likelihood="f2",verbose=FALSE)
plotfit(x,w=Inf,f2like$coefficients[1:2],nclass=30,
                 main="eq 9 likelihood\nadjusted beta")
f1like=fitadmb(x,w=Inf,likelihood="f1",verbose=FALSE)
plotfit(x,w=Inf,f1like$coefficients[1:2],nclass=30,
                 main="eq 11 likelihood\nadjusted beta")
@



\subsection{\label{sub:Fitting-mixed-scale}Fitting mixed scale detection functions}

The following is an example of a mixed effects model that can only
be fitted at present with the ADMB code and the $L_{f}$ likelihood
from eq \ref{eq:f likelihood}. We simulate 3000 objects from a half-normal
detection function truncated at \textit{w} = 50 with a random scale
where the first 2000 detected objects were generated using a larger
scale intercept $\beta_{g}$ compared to the last 1000 objects. All
objects have the same random effect distribution. We fit two models
to the data, both using the likelihood $L_{f}$ from eq \ref{eq:f likelihood},
however, one model with the covariate (mixed scale, \textit{fwlike})
and one without the covariate (random scale, \textit{flike}). Note
that the argument \textit{formula} is used to specify the covariate
model for the detection function. 

<<eval=FALSE>>=
# simulate data
x1=simdata(n=2000,w=50,beta_eps=-.5,beta=2,
          fixed=FALSE,reject=TRUE)
x2=simdata(n=1000,w=50,beta_eps=-.5,beta=1,
          fixed=FALSE,reject=TRUE)
df=data.frame(covariate=c(rep(0,length(x1)),
          rep(1,length(x2))),distance=c(x1,x2))
# fit data with covariate
fwlike=fitadmb(df,w=50,formula=~covariate,
               likelihood="f2",verbose=FALSE)
param=fwlike$coefficients[1:3]
Nhatwcov=plotfit(df$distance,w=50,par=param,nclass=30,
                 dm=model.matrix(~covariate,df),
                 main="With covariate")
Nhatwcov.se=compute_Nhat.se(par=param,fwlike$vcov[1:3,1:3],
                 x=df,w=50,dm=model.matrix(~covariate,df))
# fit data without covariate
flike=fitadmb(df,w=50,formula=~1,
              likelihood="f2",verbose=FALSE)
param=flike$coefficients[1:2]
Nhatwocov=plotfit(df$distance,w=50,par=param,nclass=30,
                 main="Without covariate")
Nhatwocov.se=compute_Nhat.se(par=param,flike$vcov[1:2,1:2],
                 x=df,w=50,dm=model.matrix(~1,df))
@


\noindent The fit of the detection functions averaged over all data
look similar for both models (Figure \ref{fig:graph005}) but the
model with the covariate is clearly better with a $\triangle$AIC
of \Sexpr{round(-2*flike$loglik+2*2-(-2*fwlike$loglik+2*3),2)}. The
estimate of abundance from the model with the covariate is \Sexpr{round(Nhatwcov,0)}
(se=\Sexpr{round(Nhatwcov.se,1)}) and without the covariate is \Sexpr{round(Nhatwocov,0)}
(se=\Sexpr{round(Nhatwocov.se,1)}). For the mixed effect model the
estimated standard deviation (\Sexpr{round(exp(fwlike$coefficients[3]),2)})
is smaller than the same quantity for the random effect model (\Sexpr{round(exp(flike$coefficients[2]),2)})
which absorbs the heterogeneity due to the missing covariate into
the random effect.

The total abundance estimates are similar, but when abundance is estimated
for each type of object (with covariate: \Sexpr{round(Nhatwcov0,0)}
(se = \Sexpr{round(Nhatwcov0.se,1)}) and \Sexpr{round(Nhatwcov1,1)}
(se = \Sexpr{round(Nhatwcov1.se,1)}); without covariate: \Sexpr{round(Nhatwocov0,0)}
(se = \Sexpr{round(Nhatwocov0.se,1)}) and  \Sexpr{round(Nhatwocov1,1)}
(se = \Sexpr{round(Nhatwocov1.se,1)}) the importance of including
the covariate becomes obvious. When using the model with the covariate,
the model fits tighter to the observed data (Figure \ref{fig:graph006})
in particular for the subset of the data with the smaller sample size,
i.e.\ x2 with covariate value = 1. On the other
hand, for the model without the covariate predicted detection probabilities
are too low for distances near zero and too high for larger distances
which results in an underestimate of abundance of those with covariate
value 1. Likewise, the abundance for objects with covariate value
0 is too high. \newpage{}


\end{document}
